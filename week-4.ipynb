{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:- As all the data cleaning part and its statistical evaluation is already done in previous weeks, so I won't be doing this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pandas library.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to load cancer dataset.\n",
    "dataframe = pd.read_csv(\"dat/cancer-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to preserve the original dataset, \n",
    "# this might come handy for later use.\n",
    "df = pd.DataFrame(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column 'id' as it will not contribute in classification, \n",
    "# as each row has a unique identifier.\n",
    "df =  df.loc[:, df.columns != 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0         M        17.99         10.38          122.80     1001.0   \n",
      "1         M        20.57         17.77          132.90     1326.0   \n",
      "2         M        19.69         21.25          130.00     1203.0   \n",
      "3         M        11.42         20.38           77.58      386.1   \n",
      "4         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2419  ...         25.38          17.33           184.60   \n",
      "1         0.1812  ...         24.99          23.41           158.80   \n",
      "2         0.2069  ...         23.57          25.53           152.50   \n",
      "3         0.2597  ...         14.91          26.50            98.87   \n",
      "4         0.1809  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# import label encoder from sklearn package.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create an object of Label Encoder.\n",
    "labelencoder_Y=LabelEncoder()\n",
    "\n",
    "# View structure of the the dataset.\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see our target varaible 'Diagnosis' at column index one. \n",
    "# Use Label Encoder to encode String or Text value into numerical values.\n",
    "# because many algorithm does not work on text data.\n",
    "df.iloc[:,0]=labelencoder_Y.fit_transform(df.iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0          1        17.99         10.38          122.80     1001.0   \n",
      "1          1        20.57         17.77          132.90     1326.0   \n",
      "2          1        19.69         21.25          130.00     1203.0   \n",
      "3          1        11.42         20.38           77.58      386.1   \n",
      "4          1        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2419  ...         25.38          17.33           184.60   \n",
      "1         0.1812  ...         24.99          23.41           158.80   \n",
      "2         0.2069  ...         23.57          25.53           152.50   \n",
      "3         0.2597  ...         14.91          26.50            98.87   \n",
      "4         0.1809  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Again see, if values of diagnosis column is labelled successfully.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
      "diagnosis        1.000000     0.730029      0.415185        0.742636   \n",
      "radius_mean      0.730029     1.000000      0.323782        0.997855   \n",
      "texture_mean     0.415185     0.323782      1.000000        0.329533   \n",
      "perimeter_mean   0.742636     0.997855      0.329533        1.000000   \n",
      "area_mean        0.708984     0.987357      0.321086        0.986507   \n",
      "\n",
      "                area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
      "diagnosis        0.708984         0.358560          0.596534        0.696360   \n",
      "radius_mean      0.987357         0.170581          0.506124        0.676764   \n",
      "texture_mean     0.321086        -0.023389          0.236702        0.302418   \n",
      "perimeter_mean   0.986507         0.207278          0.556936        0.716136   \n",
      "area_mean        1.000000         0.177028          0.498502        0.685983   \n",
      "\n",
      "                concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
      "diagnosis                  0.776614       0.330499  ...      0.776454   \n",
      "radius_mean                0.822529       0.147741  ...      0.969539   \n",
      "texture_mean               0.293464       0.071401  ...      0.352573   \n",
      "perimeter_mean             0.850977       0.183027  ...      0.969476   \n",
      "area_mean                  0.823269       0.151293  ...      0.962746   \n",
      "\n",
      "                texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "diagnosis            0.456903         0.782914    0.733825          0.421465   \n",
      "radius_mean          0.297008         0.965137    0.941082          0.119616   \n",
      "texture_mean         0.912045         0.358040    0.343546          0.077503   \n",
      "perimeter_mean       0.303038         0.970387    0.941550          0.150549   \n",
      "area_mean            0.287489         0.959120    0.959213          0.123523   \n",
      "\n",
      "                compactness_worst  concavity_worst  concave points_worst  \\\n",
      "diagnosis                0.590998         0.659610              0.793566   \n",
      "radius_mean              0.413463         0.526911              0.744214   \n",
      "texture_mean             0.277830         0.301025              0.295316   \n",
      "perimeter_mean           0.455774         0.563879              0.771241   \n",
      "area_mean                0.390410         0.512606              0.722017   \n",
      "\n",
      "                symmetry_worst  fractal_dimension_worst  \n",
      "diagnosis             0.416294                 0.323872  \n",
      "radius_mean           0.163953                 0.007066  \n",
      "texture_mean          0.105008                 0.119205  \n",
      "perimeter_mean        0.189115                 0.051019  \n",
      "area_mean             0.143570                 0.003738  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Attempt to plot a correlation matrix.\n",
    "corr_matrix = df.corr(method=\"pearson\")\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['radius_mean', 'perimeter_mean', 'area_mean', 'radius_se', 'radius_worst', 'perimeter_worst']\n"
     ]
    }
   ],
   "source": [
    "# Drop columns which have strong correlation between them, it will\n",
    "# increase the performance of the model by decreasing its complexity.\n",
    "# This will also avoid the common model 'Overfitting' problem.\n",
    "absolute_corr_matrix = corr_matrix.abs()\n",
    "\n",
    "# Create an upper triangle.\n",
    "mask = np.triu(np.ones_like(absolute_corr_matrix, dtype=bool))\n",
    "tri_df = absolute_corr_matrix.mask(mask)\n",
    "\n",
    "# Find the columns to drop.\n",
    "to_drop = [c for c in tri_df.columns if any(tri_df[c] > 0.95)]\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new reduced dataframe.\n",
    "reduced_df = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   diagnosis  texture_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
      "0          1         10.38          0.11840           0.27760          0.3001   \n",
      "1          1         17.77          0.08474           0.07864          0.0869   \n",
      "2          1         21.25          0.10960           0.15990          0.1974   \n",
      "3          1         20.38          0.14250           0.28390          0.2414   \n",
      "4          1         14.34          0.10030           0.13280          0.1980   \n",
      "\n",
      "   concave points_mean  symmetry_mean  fractal_dimension_mean  texture_se  \\\n",
      "0              0.14710         0.2419                 0.07871      0.9053   \n",
      "1              0.07017         0.1812                 0.05667      0.7339   \n",
      "2              0.12790         0.2069                 0.05999      0.7869   \n",
      "3              0.10520         0.2597                 0.09744      1.1560   \n",
      "4              0.10430         0.1809                 0.05883      0.7813   \n",
      "\n",
      "   perimeter_se  ...  symmetry_se  fractal_dimension_se  texture_worst  \\\n",
      "0         8.589  ...      0.03003              0.006193          17.33   \n",
      "1         3.398  ...      0.01389              0.003532          23.41   \n",
      "2         4.585  ...      0.02250              0.004571          25.53   \n",
      "3         3.445  ...      0.05963              0.009208          26.50   \n",
      "4         5.438  ...      0.01756              0.005115          16.67   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(reduced_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset into two dataframes.\n",
    "# X contains independent variables.\n",
    "X=reduced_df.iloc[:,1:24].values \n",
    "# Y is the dependent variable.\n",
    "Y=reduced_df.iloc[:,0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Attempt to split dataset into training and test dataset.\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "# z = (x - u) / s\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to train a logistic regression model on the specified training dataset.\n",
    "def logreg (X_train, Y_train):\n",
    "    \"\"\"\n",
    "        Trains a logisitic regretion model.\n",
    "        \n",
    "        Parameters\n",
    "        ------\n",
    "        X_train : The training dataset of independent variables.\n",
    "        Y_train : The training dataset of dependent variable.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    # Create a logistic regression model.\n",
    "    log=LogisticRegression (random_state=0)\n",
    "    # Train the model on the specified training dataset.\n",
    "    log.fit(X_train, Y_train)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a logistic regression model.\n",
    "logreg = logreg(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAccuracy(Y_test, prediction):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(Y_test, prediction)\n",
    "    # In our case 'Malignant' is a positive class.\n",
    "\n",
    "    # The diagonis was 'Malignat' and predicted as 'Malignant'.\n",
    "    TP=cm[0][0]\n",
    "    # The diagonis was 'Not Malignat' and predicted as 'Not Malignant'.\n",
    "    TN=cm[1][1]\n",
    "    # The diagonis was 'Malignat' and predicted as 'Not Malignant'.\n",
    "    FN=cm[1][0]\n",
    "    # The diagonis was 'Not Malignat' and predicted as 'Malignant'.\n",
    "    FP=cm[0][1]\n",
    "    return (TP+TN)/(TP+TN+FN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the dependent variable using the previously trained logistic regression model.\n",
    "logreg_prediction = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of logistic regression model= 0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy of logistic regression model=\", findAccuracy(Y_test, logreg_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to train a Decision tree classified model on the specified training dataset.\n",
    "def dectree (X_train, Y_train):\n",
    "    \"\"\"\n",
    "        Trains a Decision tree classifier model.\n",
    "        \n",
    "        Parameters\n",
    "        ------\n",
    "        X_train : The training dataset of independent variables.\n",
    "        Y_train : The training dataset of dependent variable.\n",
    "    \"\"\"\n",
    "    from sklearn import tree\n",
    "    # Create a Decision Tree Classification model.\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "    # Train the model on the specified training dataset.\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Decision Tree Classifier model.\n",
    "dectree = dectree(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the dependent variable using the previously trained Decision Tree Classification model.\n",
    "dectree_prediction = dectree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of Decision Tree Classification model= 0.9300699300699301\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy of Decision Tree Classification model=\", findAccuracy(Y_test, dectree_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to train a Random forest classification model on the specified training dataset.\n",
    "def randfor (X_train, Y_train):\n",
    "    \"\"\"\n",
    "        Trains a Random forest classification model.\n",
    "        \n",
    "        Parameters\n",
    "        ------\n",
    "        X_train : The training dataset of independent variables.\n",
    "        Y_train : The training dataset of dependent variable.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Create a Random Forest Classification model.\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    # Train the model on the specified training dataset.\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Random Forest Classifier model.\n",
    "randfor = randfor(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the dependent variable using the previously trained Random Forest Classification model.\n",
    "randfor_prediction = randfor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of Random Forest model= 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy of Random Forest model=\", findAccuracy(Y_test, randfor_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
